The document describes agentic retrieval in Azure AI Search, a new multi-query pipeline designed for complex question answering in chat and copilot applications. It uses a large language model (LLM) to break down complex queries into focused subqueries, runs them in parallel, semantically reranks results, and synthesizes a unified response with grounding data, source references, and execution details. The feature supports Retrieval Augmented Generation (RAG) patterns and agent-to-agent workflows, is currently in public preview, and is integrated through a knowledge base object in Azure AI Search. The document details the architecture, workflow, required components, integration requirements, usage scenarios, pricing, and cost estimation for agentic retrieval, emphasizing its benefits for improving recall and handling complex queries with chat context and proprietary content.