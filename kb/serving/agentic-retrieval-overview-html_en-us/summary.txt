The document provides a comprehensive overview of agentic retrieval in Azure AI Search, a multi-query pipeline designed for complex question answering in chat and copilot applications. It explains the architecture, workflow, and components involved, including the use of large language models (LLMs) for query planning and semantic reranking for query execution. The document details use cases, integration requirements, pricing models, and cost estimation examples, emphasizing the benefits of improved recall and modular responses. It also offers guidance on getting started, available quickstarts, tutorials, and tips for controlling costs, highlighting the feature's current public preview status and its dependency on premium features.