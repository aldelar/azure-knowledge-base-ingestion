The document provides a comprehensive overview of agentic retrieval in Azure AI Search, a multi-query pipeline designed for complex question answering in chat and copilot applications. It explains the architecture, workflow, and components involved, including the use of large language models (LLMs) for query planning and semantic reranking for query execution. The document details use cases, integration requirements, pricing models, and cost estimation examples, emphasizing the benefits of improved recall and modular responses for generative AI applications. It also offers guidance on getting started, available resources, and tips for controlling costs.